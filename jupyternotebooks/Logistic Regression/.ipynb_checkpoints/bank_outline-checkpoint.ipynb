{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cleared-month",
   "metadata": {},
   "source": [
    "## BINARY CLASSIFICATION WITH LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-planner",
   "metadata": {},
   "source": [
    "### 1.1 Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Pandas, Numpy, Seaborn, Matplotlib, sqlalchemy, pymysql and getpass to protect our password\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import getpass\n",
    "password=getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-cloud",
   "metadata": {},
   "source": [
    "### 1.2 Connection to sql "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection string:\n",
    "\n",
    "connection_string='mysql+pymysql://root:'+password+'@localhost/bank'\n",
    "engine=create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query as a df:\n",
    "\n",
    "df= pd.read_sql_query('''\n",
    "select l.loan_id, l.status, count(distinct t.trans_id) as nooftrans, DATEDIFF(19981231, convert(a.date,date)) as ageindays, \n",
    "d.A12 as 95unemp, d.A13 as 96unemp, dp.type,\n",
    "l.amount as loanamount, c.birth_number, d.A15 as crime95, d.A16 as crime96,\n",
    "round((l.amount-l.payments)/l.amount,2) as ratiopaid\n",
    "from loan l\n",
    "left join trans t\n",
    "using(account_id)\n",
    "left join account a\n",
    "using(account_id)\n",
    "left join district d\n",
    "on a.district_id = d.A1\n",
    "left join disp dp\n",
    "on a.account_id= dp.account_id \n",
    "left join client c\n",
    "using(client_id)\n",
    "WHERE l.status in ('A','B') AND dp.type = 'OWNER'\n",
    "group by loan_id, l.amount, status, d.A12, d.A13, c.birth_number, d.A15, d.A16, DATEDIFF(19981231, convert(a.date,date)),\n",
    "dp.type, round((l.amount-l.payments)/l.amount,2)\n",
    "''', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-climate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use head to confirm the df works as expected \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-jamaica",
   "metadata": {},
   "source": [
    "###  2. EDA - Exploratory Data Analysis - get to know the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of records, columns, null values and data types:\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run descriptive statistics on numerical values:\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types in a different view\n",
    "\n",
    "df.dtypes\n",
    "\n",
    "# Looks like we could drop loan_id and \"birth_number\"..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd44be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After having a closer look at the unique values of \"birth_number\", it looks like it could actually add value...\n",
    "# We could potentially extract gender and actual birthdates in date format, we will revisit during cleaning and wrangling\n",
    "\n",
    "df.birth_number.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db2db8",
   "metadata": {},
   "source": [
    "### 2.1 Histograms or boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767dde0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize \"number of transactions\" based on \"status\" with a Histogram:\n",
    "\n",
    "sns.displot(df, x='nooftrans', hue='status');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d91c380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize \"total loan amount\" based on \"status\" with a Boxplot:\n",
    "\n",
    "sns.barplot(x='loanamount', y='status', data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9c5e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check to understand how many counts of each category we have in our DataFrame\n",
    "\n",
    "df['status'].value_counts()\n",
    "\n",
    "# We can already see that the model we end up is very likely to be inbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ac548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to visualize \"age of account\" with another Histogram:\n",
    "\n",
    "sns.displot(df['ageofaccount']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ffe825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising 95' and 96' unemployment to decide whether we want to drop one of the two...\n",
    "\n",
    "fig = sns.kdeplot(df['95unemp'], shade=True, color=\"r\")\n",
    "fig = sns.kdeplot(df['96unemp'], shade=True, color=\"b\")\n",
    "plt.show()\n",
    "\n",
    "# We could alternatively define a new column with the average of both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d139d943",
   "metadata": {},
   "source": [
    "### 2.2 Check for multicollinearity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d7974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick glance at multicollinearity using a table \"snapshot\" view:\n",
    "\n",
    "correlation=df.corr()\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b78ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn heatmap to visualise correlation in a more eye-friendly way:\n",
    "\n",
    "corr_matrix=df.corr(method='pearson')\n",
    "fig, ax=plt.subplots(figsize =(10,8))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "ax=sns.heatmap(corr_matrix, mask=mask, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-drive",
   "metadata": {},
   "source": [
    "### 2. 3 Clean and wrangling steps "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f498dee6",
   "metadata": {},
   "source": [
    "### Potential steps to follow when iterating:\n",
    "\n",
    " - Bucket into categories any fields\n",
    " - Should we drop any columns ? (iterative process) - we could drop loan_id!\n",
    " - Create avg of criminality / unemployment rate?\n",
    " - Crime - divide population?\n",
    " - Change duration to object type / categorical - 12,24,36,48,72  \n",
    " - Same for operation field \n",
    " - Drop highly correlated fields\n",
    " - Bring in any missing fields\n",
    " - Change unemployment into High - Mid - Low\n",
    " - Split the data into num and cat --- > diff options cleaning / scaling \n",
    " - Feature engineering - take an existing column and make it more useful\n",
    " - Check for multicollinearity\n",
    " - Extract gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2199a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \"loan_id\" from our DataFrame since it is not adding any value\n",
    "\n",
    "df.drop(['loan_id', 'type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e29550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the column was actually dropped\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0608477c",
   "metadata": {},
   "source": [
    "### 2. 4 Pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44632d73",
   "metadata": {},
   "source": [
    " - label / encode categorical columns \n",
    " - scale numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f55b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for categorical data (\"status\") and visualize it:\n",
    "\n",
    "cat=df.select_dtypes(include=object)\n",
    "cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3667ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new categorical Dataframe with only 'B' status as a boolean:\n",
    "\n",
    "categorical=pd.get_dummies(cat,columns=['status'],drop_first=True)\n",
    "categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf4dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical scaling: import Normalizer function:\n",
    "\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8ccad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create numerical DataFrame \"X\" and visualise it:\n",
    "\n",
    "X = df.select_dtypes(include=np.number)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72f4aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the numerical features to be normalised (gaussian distribution)\n",
    "# Optional with logistic regresssion but might help model\n",
    "\n",
    "scaler=Normalizer().fit(X)\n",
    "scaled=scaler.transform(X)\n",
    "scaled_X=pd.DataFrame(scaled)\n",
    "scaled_X.head()\n",
    "\n",
    "# Once we scale, we convert the array back to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e1f2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO NOTE: if you had more categorical features than just the label (status) we would concat\n",
    "# X=np.concatenate((scaled_X, categorical)axis=1) --- This would bring back categorical data with numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-teaching",
   "metadata": {},
   "source": [
    "### 2.5 Split off the dependant variable (label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = dependant variable \"status\"\n",
    "\n",
    "y = categorical['status_B']\n",
    "\n",
    "# Independant variables are scaled_X -- Let´s redefine X:\n",
    "\n",
    "X = scaled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a614e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of our Boolean dependant variable \"y\":\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-article",
   "metadata": {},
   "source": [
    "### 2.6 Train test split, get LOG REG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Logistic Regression model from Scikit learn:\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e5f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose what amount(%) of data is destined to training the model and which (%) for testing:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-management",
   "metadata": {},
   "source": [
    "## 3. Apply model and train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification=LogisticRegression(solver='liblinear', multi_class='ovr').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47151ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to the parameters as wished\n",
    "# check scikit learn website -- logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-depth",
   "metadata": {},
   "source": [
    "### 3.1 Evaluate accuracy and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy of the model:\n",
    "\n",
    "probabilities=classification.predict_proba(X_test)\n",
    "preds=probabilities[:,1]\n",
    "import sklearn.metrics as metrics\n",
    "fpr, tpr, threshold=metrics.roc_curve(y_test, preds)\n",
    "roc_auc=metrics.auc(fpr,tpr)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa370ec",
   "metadata": {},
   "source": [
    "#### 3.1.1 Next steps\n",
    "\n",
    "+ Visualise the accuracy of the predictions in some ways \n",
    "\n",
    "+ also think about - is there something I could do to improve my model accuracy?? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-mother",
   "metadata": {},
   "source": [
    "### 3.2 Visualising accuracy - ROC / AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3556c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve plot visualisation:\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr,tpr, label='AUC'%roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.ylabel('true positive rate')\n",
    "plt.xlabel('false positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e6812c",
   "metadata": {},
   "source": [
    "### 3.3 Visualising accuracy - Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0557d3b",
   "metadata": {},
   "source": [
    "##### definitions \n",
    "+ tpr = true positive rate \n",
    "+ fpr = false positive rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb7d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import accuracy score model from Scikitlearn, definde variable predictions:\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = classification.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2529a199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and run Confusion Matrix model and Plot\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "accuracy_score(y_test,predictions)\n",
    "confusion_matrix(y_test, predictions)\n",
    "plot_confusion_matrix(classification,X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-aaron",
   "metadata": {},
   "source": [
    "### 3.4 Data is highly imbalanced\n",
    "\n",
    "this is affecting the accuracy of our predictions \n",
    "- what can be done to resolve that ?\n",
    "\n",
    "\n",
    "+ option 1 - SMOTE \n",
    "\n",
    "+ option 2 - TOMEK LINKS \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE -- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82b0878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOMEK LINKS -- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
